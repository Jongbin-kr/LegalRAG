{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO/FSWcJR5eVO6vNevl0wmq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l31MB2_2tkbX","executionInfo":{"status":"ok","timestamp":1717981846284,"user_tz":-540,"elapsed":21407,"user":{"displayName":"김보영","userId":"03119726252609230646"}},"outputId":"e47caeb7-cff6-4f61-81a2-f439031fcdfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/univ/4/nlp/alpha\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My Drive/univ/4/nlp/alpha"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","# CSV 파일 읽기\n","csv_file = 'AlphaMist_total_result.csv'\n","df_total = pd.read_csv(csv_file)\n","df_total['답변'] = df_total['답변'].str.extract(r'답변:\\s*(.*)')\n","df_total['RAG  답변'] = df_total['RAG  답변'].str.extract(r'response:\\s*(.*)')\n","# 새로운 DataFrame을 확인\n","print(df_total['답변'].head())\n","print(df_total['RAG  답변'].head())\n","base3_csv_file = 'baseline3_AlphaMist_result.csv'\n","df = pd.read_csv(base3_csv_file)\n","df['response']=df['response'].str.extract(r'답변:\\s*(.*)')\n","print(df['response'].head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p9dVd0MRt5of","executionInfo":{"status":"ok","timestamp":1717981874806,"user_tz":-540,"elapsed":326,"user":{"displayName":"김보영","userId":"03119726252609230646"}},"outputId":"ed1ee815-f11c-464c-c561-ef91dacf5bf4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["0    피해자의 맥락에서 제공한 정보에 따르면 피고인은 폭행죄에 대해 형사처벌을 받을 수 ...\n","1    도로교통법 제44조 제1항에 따르면 자동차운전면허가 없는 사람이 도로에서 자동차를 ...\n","2                                                  NaN\n","3    위 상황은 여러 가지 법령에 따라 처벌을 받을 수 있습니다. 다음은 구체적인 내용입니다:\n","4    1. 예, 피해자의 죽음으로 인해 살인죄로 처벌받을 수 있습니다. 살인죄는 일반적으...\n","Name: 답변, dtype: object\n","0    1. 위증: 위 판례에서 설명한 것처럼 피고인은 자신의 기억에 반하는 허위의 진술을...\n","1    1. 위증: 위 판례에서 설명한 것처럼 피고인은 사고 후 증언에서 허위 진술을 한 ...\n","2    피해자를 살해한 것은 형법 29조(존속살인)와 형법 26조(사체은닉)에 따라 처벌될...\n","3    피고인이 자신의 증인인 B를 유인하여 위증을 저지른 행위는 형법 288조에 따라 처...\n","4                                                  NaN\n","Name: RAG  답변, dtype: object\n","0    위 판례에서는 피해자가 피고인에게 폭행당한 것으로 피고인이 폭행죄로 처벌받을 수 있...\n","1    피고인은 위증과 방조로 인해 처벌을 받을 수 있습니다. 위증은 법원 절차에서 거짓 ...\n","2    1. 존속살인: 형법 제250조 제2항에 따라 누군가 존속인을 살해하는 경우 처벌받...\n","3                                                  NaN\n","4    1. 제가 저지른 행위는 살인죄로 처벌받을 수 있습니다. 살인죄는 누군가를 죽이거나...\n","Name: response, dtype: object\n"]}]},{"cell_type":"code","source":["print(\"답변 열의 유효한 값 개수:\", df_total['답변'].notna().sum())\n","print(\"RAG  답변 열의 유효한 값 개수:\", df_total['RAG  답변'].notna().sum())\n","print(\"response 열의 유효한 값 개수:\", df['response'].notna().sum())\n","valid_indices = df[df_total['답변'].notna() & df_total['RAG  답변'].notna()&df['response'].notna()].index\n","print(\"유효한 값 개수:\", len(valid_indices))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PmZIDBW0MOZQ","executionInfo":{"status":"ok","timestamp":1717981991038,"user_tz":-540,"elapsed":299,"user":{"displayName":"김보영","userId":"03119726252609230646"}},"outputId":"d1d65471-b5e4-44e3-a5f3-684b7362f6c1"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["답변 열의 유효한 값 개수: 137\n","RAG  답변 열의 유효한 값 개수: 100\n","response 열의 유효한 값 개수: 124\n","유효한 값 개수: 62\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"UI0KdswBudIH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#baseline 1 mistral\n","from metrics import exact_match_score, accuracy, f1\n","valid_indices = df[df_total['답변'].notna() & df_total['RAG  답변'].notna()&df['response'].notna()].index\n","preds = df_total.loc[valid_indices, '답변'].tolist()\n","ground_truths = df_total.loc[valid_indices, '법령의 적용'].tolist()\n","f1_score = f1(preds, [[gt] for gt in ground_truths])\n","print(f\"F1 Score: {f1_score}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Le7KpBe5uZrA","executionInfo":{"status":"ok","timestamp":1717982402400,"user_tz":-540,"elapsed":310,"user":{"displayName":"김보영","userId":"03119726252609230646"}},"outputId":"fea66c6e-913e-4e86-8dc7-c756cb721361"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 Score: 2.326578043833071%\n"]}]},{"cell_type":"code","source":["#baseline3-1 mistral\n","from metrics import exact_match_score, accuracy, f1\n","valid_indices = df[df_total['답변'].notna() & df_total['RAG  답변'].notna()&df['response'].notna()].index\n","preds = df.loc[valid_indices, 'response'].tolist()\n","ground_truths = df.loc[valid_indices, '쿼리 법령의 적용'].tolist()\n","f1_score = f1(preds, [[gt] for gt in ground_truths])\n","print(f\"F1 Score: {f1_score}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XIkdmgrMukRJ","executionInfo":{"status":"ok","timestamp":1717982149400,"user_tz":-540,"elapsed":335,"user":{"displayName":"김보영","userId":"03119726252609230646"}},"outputId":"9ba22ca0-598a-4385-88bb-c402545bd6ad"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 Score: 6.079482467451576%\n"]}]},{"cell_type":"code","source":["!pip install nltk rouge_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6S_Y5ak1yWWC","executionInfo":{"status":"ok","timestamp":1717982185024,"user_tz":-540,"elapsed":9129,"user":{"displayName":"김보영","userId":"03119726252609230646"}},"outputId":"46444433-585d-435b-d2cc-bb8c71983bc8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=25db4f79064de421775e1ad431afd7bdcc436a4864f4b793fce599a2063c96ab\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n"]}]},{"cell_type":"code","source":["#baseline3-1 mistral\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from rouge_score import rouge_scorer\n","bleu_scores = [sentence_bleu([gt.split()], pred.split()) for pred, gt in zip(preds, ground_truths)]\n","bleu_score = 100 * np.mean(bleu_scores)\n","print(f\"BLEU Score: {bleu_score}%\")\n","smoothing = SmoothingFunction().method4\n","\n","bleu1_scores = [sentence_bleu([gt.split()], pred.split(), weights=(1, 0, 0, 0), smoothing_function=smoothing) for pred, gt in zip(preds, ground_truths)]\n","bleu2_scores = [sentence_bleu([gt.split()], pred.split(), weights=(0.5, 0.5, 0, 0), smoothing_function=smoothing) for pred, gt in zip(preds, ground_truths)]\n","\n","bleu1_score = 100 * np.mean(bleu1_scores)\n","bleu2_score = 100 * np.mean(bleu2_scores)\n","\n","print(f\"BLEU-1 Score: {bleu1_score}%\")\n","print(f\"BLEU-2 Score: {bleu2_score}%\")\n","scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n","rouge1_scores = []\n","rouge2_scores = []\n","rougeL_scores = []\n","\n","for pred, gt in zip(preds, ground_truths):\n","    scores = scorer.score(gt, pred)\n","    rouge1_scores.append(scores['rouge1'].fmeasure)\n","    rouge2_scores.append(scores['rouge2'].fmeasure)\n","    rougeL_scores.append(scores['rougeL'].fmeasure)\n","\n","rouge1_score = 100 * np.mean(rouge1_scores)\n","rouge2_score = 100 * np.mean(rouge2_scores)\n","rougeL_score = 100 * np.mean(rougeL_scores)\n","\n","print(f\"ROUGE-1 Score: {rouge1_score}%\")\n","print(f\"ROUGE-2 Score: {rouge2_score}%\")\n","print(f\"ROUGE-L Score: {rougeL_score}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbPCmh8oyBvA","executionInfo":{"status":"ok","timestamp":1717982433879,"user_tz":-540,"elapsed":303,"user":{"displayName":"김보영","userId":"03119726252609230646"}},"outputId":"92c78382-a18a-4424-ba14-89dea7438ccb"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["BLEU Score: 5.164377842697283e-156%\n","BLEU-1 Score: 1.301811378551462%\n","BLEU-2 Score: 0.6178932617721834%\n","ROUGE-1 Score: 5.953241362943766%\n","ROUGE-2 Score: 1.3309773574395085%\n","ROUGE-L Score: 5.820218416485502%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]}]},{"cell_type":"code","source":["#baseline2-1 mistral\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from rouge_score import rouge_scorer\n","preds = df_total.loc[valid_indices, 'RAG  답변'].tolist()\n","ground_truths = df_total.loc[valid_indices, '법령의 적용'].tolist()\n","f1_score = f1(preds, [[gt] for gt in ground_truths])\n","print(f\"F1 Score: {f1_score}%\")\n","bleu_scores = [sentence_bleu([gt.split()], pred.split()) for pred, gt in zip(preds, ground_truths)]\n","bleu_score = 100 * np.mean(bleu_scores)\n","print(f\"BLEU Score: {bleu_score}%\")\n","smoothing = SmoothingFunction().method4\n","\n","bleu1_scores = [sentence_bleu([gt.split()], pred.split(), weights=(1, 0, 0, 0), smoothing_function=smoothing) for pred, gt in zip(preds, ground_truths)]\n","bleu2_scores = [sentence_bleu([gt.split()], pred.split(), weights=(0.5, 0.5, 0, 0), smoothing_function=smoothing) for pred, gt in zip(preds, ground_truths)]\n","\n","bleu1_score = 100 * np.mean(bleu1_scores)\n","bleu2_score = 100 * np.mean(bleu2_scores)\n","\n","print(f\"BLEU-1 Score: {bleu1_score}%\")\n","print(f\"BLEU-2 Score: {bleu2_score}%\")\n","scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n","rouge1_scores = []\n","rouge2_scores = []\n","rougeL_scores = []\n","\n","for pred, gt in zip(preds, ground_truths):\n","    scores = scorer.score(gt, pred)\n","    rouge1_scores.append(scores['rouge1'].fmeasure)\n","    rouge2_scores.append(scores['rouge2'].fmeasure)\n","    rougeL_scores.append(scores['rougeL'].fmeasure)\n","\n","rouge1_score = 100 * np.mean(rouge1_scores)\n","rouge2_score = 100 * np.mean(rouge2_scores)\n","rougeL_score = 100 * np.mean(rougeL_scores)\n","\n","print(f\"ROUGE-1 Score: {rouge1_score}%\")\n","print(f\"ROUGE-2 Score: {rouge2_score}%\")\n","print(f\"ROUGE-L Score: {rougeL_score}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z8mU4AOryqmf","executionInfo":{"status":"ok","timestamp":1717982504037,"user_tz":-540,"elapsed":4,"user":{"displayName":"김보영","userId":"03119726252609230646"}},"outputId":"1806f968-72f6-4579-a6fb-7640eff368c6"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 Score: 3.4125223132182407%\n","BLEU Score: 5.478777123170413e-155%\n","BLEU-1 Score: 1.3336300917878159%\n","BLEU-2 Score: 0.6270184657111469%\n","ROUGE-1 Score: 8.338882774271939%\n","ROUGE-2 Score: 0.5309139784946236%\n","ROUGE-L Score: 8.338882774271939%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]}]}]}