{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for each baseline\n",
    "- baseline 1~3 각각에 대하여, gpt 답변과 AlphaMistral 답변이 나온 경우에 대해서 측정.\n",
    "- 즉, baseline별로 AlphaMistral 답변을 얻지 못한 경우가 있어서, n값이 `137`, `100`, `124`로 다르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate f1, BLEU, ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./results/final_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### preds: mst_response_3, groundtruth: gpt_response_3 (n=124\n",
      "f1 score: 24.402739114531315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dieyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\dieyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\dieyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 4.085255349545449%\n",
      "BLEU-1 Score: 14.585558432172718%\n",
      "BLEU-2 Score: 9.315604202445105%\n",
      "ROUGE-1 Score: 51.443019533237454%\n",
      "ROUGE-2 Score: 30.02170533140501%\n",
      "ROUGE-L Score: 44.855783606782175%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "### preds: mst_response_2, groundtruth: gpt_response_2 (n=100\n",
      "f1 score: 19.160554816466206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dieyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\dieyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\dieyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 1.1105968997103126%\n",
      "BLEU-1 Score: 14.921234899225801%\n",
      "BLEU-2 Score: 7.734512867579727%\n",
      "ROUGE-1 Score: 33.101862508044285%\n",
      "ROUGE-2 Score: 14.11336533836534%\n",
      "ROUGE-L Score: 31.793893679487223%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "### preds: mst_response_1, groundtruth: gpt_response_1 (n=137\n",
      "f1 score: 22.711123002700024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dieyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\dieyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 2.4369614721012964%\n",
      "BLEU-1 Score: 18.498069150141447%\n",
      "BLEU-2 Score: 10.643438238599435%\n",
      "ROUGE-1 Score: 29.25439036721704%\n",
      "ROUGE-2 Score: 12.22327388833793%\n",
      "ROUGE-L Score: 28.23379768821843%\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from metrics import f1, calculate_bleu_scores, calculate_rouge_scores\n",
    "\n",
    "for preds, grountruths in [('mst_response_3', 'gpt_response_3'), ('mst_response_2', 'gpt_response_2'), ('mst_response_1', 'gpt_response_1')]:\n",
    "    inter_df = df.loc[:, [preds, grountruths]].dropna()\n",
    "    print(f\"### preds: {preds}, groundtruth: {grountruths} (n={len(inter_df)}\")\n",
    "    \n",
    "    preds = inter_df[preds].tolist()\n",
    "        \n",
    "    \n",
    "    grountruths = inter_df[grountruths].tolist()\n",
    "    \n",
    "    f1_score = f1(preds, grountruths)\n",
    "    bleu_scores = calculate_bleu_scores(preds, grountruths)\n",
    "    rouge_scores = calculate_rouge_scores(preds, grountruths)\n",
    "    \n",
    "    print('\\n\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### preds: mst_laws_1, groundtruth: 쿼리 법령명 (n=137)\n",
      "true_positive: 0, false_positive: 80, false_negative: 978\n",
      "precision: 0.0, recall: 0.0, f1: 0.0\n",
      "\n",
      "\n",
      "\n",
      "### preds: mst_laws_2, groundtruth: 쿼리 법령명 (n=100)\n",
      "true_positive: 1, false_positive: 76, false_negative: 760\n",
      "precision: 0.012987012987012988, recall: 0.001314060446780552, f1: 0.0023866346779837324\n",
      "\n",
      "\n",
      "\n",
      "### preds: mst_laws_3, groundtruth: 쿼리 법령명 (n=124)\n",
      "true_positive: 112, false_positive: 1000, false_negative: 694\n",
      "precision: 0.10071942446043165, recall: 0.13895781637717122, f1: 0.11678832068060992\n",
      "\n",
      "\n",
      "\n",
      "### preds: gpt_laws_1, groundtruth: 쿼리 법령명 (n=166)\n",
      "true_positive: 6, false_positive: 62, false_negative: 1158\n",
      "precision: 0.08823529411764706, recall: 0.005154639175257732, f1: 0.009740259635963065\n",
      "\n",
      "\n",
      "\n",
      "### preds: gpt_laws_2, groundtruth: 쿼리 법령명 (n=166)\n",
      "true_positive: 3, false_positive: 31, false_negative: 1161\n",
      "precision: 0.08823529411764706, recall: 0.002577319587628866, f1: 0.005008347190258667\n",
      "\n",
      "\n",
      "\n",
      "### preds: gpt_laws_3, groundtruth: 쿼리 법령명 (n=166)\n",
      "true_positive: 68, false_positive: 619, false_negative: 1096\n",
      "precision: 0.09898107714701601, recall: 0.058419243986254296, f1: 0.07347379748025992\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from metrics import calcuate_laws_match\n",
    "\n",
    "for preds in ('mst_laws_1', 'mst_laws_2', 'mst_laws_3', 'gpt_laws_1', 'gpt_laws_2', 'gpt_laws_3'):\n",
    "    grountruths = '쿼리 법령명'\n",
    "    inter_df = df.loc[:, [preds, grountruths]].dropna()\n",
    "    print(f\"### preds: {preds}, groundtruth: {grountruths} (n={len(inter_df)})\")\n",
    "    \n",
    "    groundtruths = inter_df[grountruths].tolist()\n",
    "    preds = inter_df[preds].tolist()\n",
    "    \n",
    "    calcuate_laws_match(preds, groundtruths)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate for intersection dataset\n",
    "- baseline 1~3 모두 답변이 나온 경우에 대해서만 평가\n",
    "- 각 baseline에서 답변이 나오지 않은 데이터 샘플이 다 달라서, `n=62`로 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./results/final_result.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### preds: mst_response_3, groundtruth: gpt_response_3 (n=62)\n",
      "f1 score: 25.594204686390526\n",
      "BLEU Score: 4.0269079261449665%\n",
      "BLEU-1 Score: 15.602997949253425%\n",
      "BLEU-2 Score: 9.844203121580358%\n",
      "ROUGE-1 Score: 55.30066111356066%\n",
      "ROUGE-2 Score: 32.946142956098214%\n",
      "ROUGE-L Score: 47.85146897254625%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "### preds: mst_response_2, groundtruth: gpt_response_2 (n=62)\n",
      "f1 score: 20.321798965940374\n",
      "BLEU Score: 1.1253396235166093%\n",
      "BLEU-1 Score: 15.801877533273851%\n",
      "BLEU-2 Score: 8.290233308447197%\n",
      "ROUGE-1 Score: 34.24301501840787%\n",
      "ROUGE-2 Score: 14.016692686047522%\n",
      "ROUGE-L Score: 32.550845181076745%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "### preds: mst_response_1, groundtruth: gpt_response_1 (n=62)\n",
      "f1 score: 22.725708907181563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dieyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\dieyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\dieyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\dieyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\dieyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\dieyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\dieyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\dieyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 2.504138001151585%\n",
      "BLEU-1 Score: 18.474611717258398%\n",
      "BLEU-2 Score: 10.518611462069204%\n",
      "ROUGE-1 Score: 25.945538197253697%\n",
      "ROUGE-2 Score: 8.710752102604449%\n",
      "ROUGE-L Score: 24.72827054853444%\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from metrics import f1, calculate_bleu_scores, calculate_rouge_scores\n",
    "\n",
    "for preds, grountruths in [('mst_response_3', 'gpt_response_3'), ('mst_response_2', 'gpt_response_2'), ('mst_response_1', 'gpt_response_1')]:\n",
    "    inter_df = df.loc[:, [preds, grountruths]].dropna()\n",
    "    print(f\"### preds: {preds}, groundtruth: {grountruths} (n={len(inter_df)})\")\n",
    "    \n",
    "    preds = inter_df[preds].tolist()\n",
    "        \n",
    "    \n",
    "    grountruths = inter_df[grountruths].tolist()\n",
    "    \n",
    "    f1_score = f1(preds, grountruths)\n",
    "    bleu_scores = calculate_bleu_scores(preds, grountruths)\n",
    "    rouge_scores = calculate_rouge_scores(preds, grountruths)\n",
    "    \n",
    "    print('\\n\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### preds: mst_laws_1, groundtruth: 쿼리 법령명 (n=62)\n",
      "true_positive: 0, false_positive: 40, false_negative: 472\n",
      "precision: 0.0, recall: 0.0, f1: 0.0\n",
      "\n",
      "\n",
      "\n",
      "### preds: mst_laws_2, groundtruth: 쿼리 법령명 (n=62)\n",
      "true_positive: 1, false_positive: 48, false_negative: 471\n",
      "precision: 0.02040816326530612, recall: 0.00211864406779661, f1: 0.003838771422681179\n",
      "\n",
      "\n",
      "\n",
      "### preds: mst_laws_3, groundtruth: 쿼리 법령명 (n=62)\n",
      "true_positive: 75, false_positive: 489, false_negative: 397\n",
      "precision: 0.13297872340425532, recall: 0.15889830508474576, f1: 0.14478764429158777\n",
      "\n",
      "\n",
      "\n",
      "### preds: gpt_laws_1, groundtruth: 쿼리 법령명 (n=62)\n",
      "true_positive: 1, false_positive: 24, false_negative: 471\n",
      "precision: 0.04, recall: 0.00211864406779661, f1: 0.004024144773672217\n",
      "\n",
      "\n",
      "\n",
      "### preds: gpt_laws_2, groundtruth: 쿼리 법령명 (n=62)\n",
      "true_positive: 1, false_positive: 16, false_negative: 471\n",
      "precision: 0.058823529411764705, recall: 0.00211864406779661, f1: 0.004089979482989784\n",
      "\n",
      "\n",
      "\n",
      "### preds: gpt_laws_3, groundtruth: 쿼리 법령명 (n=62)\n",
      "true_positive: 32, false_positive: 215, false_negative: 440\n",
      "precision: 0.12955465587044535, recall: 0.06779661016949153, f1: 0.08901251693422135\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from metrics import calcuate_laws_match\n",
    "\n",
    "for preds in ('mst_laws_1', 'mst_laws_2', 'mst_laws_3', 'gpt_laws_1', 'gpt_laws_2', 'gpt_laws_3'):\n",
    "    grountruths = '쿼리 법령명'\n",
    "    inter_df = df.loc[:, [preds, grountruths]].dropna()\n",
    "    print(f\"### preds: {preds}, groundtruth: {grountruths} (n={len(inter_df)})\")\n",
    "    \n",
    "    groundtruths = inter_df[grountruths].tolist()\n",
    "    preds = inter_df[preds].tolist()\n",
    "    \n",
    "    calcuate_laws_match(preds, groundtruths)\n",
    "    print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
